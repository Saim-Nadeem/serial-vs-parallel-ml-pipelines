{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9da43e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
    "from dask.distributed import wait\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "import coiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc510ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-13 01:28:51,769][INFO    ][coiled] Fetching latest package priorities...\n",
      "[2025-05-13 01:28:51,771][INFO    ][coiled.package_sync] Resolving your local Python312 Python environment...\n",
      "[2025-05-13 01:28:52,550][INFO    ][coiled.package_sync] Scanning 129 python packages...\n",
      "[2025-05-13 01:28:53,611][INFO    ][coiled] Running pip check...\n",
      "[2025-05-13 01:28:54,723][INFO    ][coiled] Validating environment...\n",
      "[2025-05-13 01:28:59,967][INFO    ][coiled] Creating wheel for ~\\AppData\\Roaming\\Python\\Python312\\site-packages\\win32\\lib...\n",
      "[2025-05-13 01:28:59,972][INFO    ][coiled] Creating wheel for ~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pythonwin...\n",
      "[2025-05-13 01:28:59,979][INFO    ][coiled] Creating wheel for ~\\AppData\\Roaming\\Python\\Python312\\site-packages\\win32...\n",
      "[2025-05-13 01:28:59,986][INFO    ][coiled] Uploading coiled_local_lib...\n",
      "[2025-05-13 01:29:00,886][INFO    ][coiled] Uploading coiled_local_pythonwin...\n",
      "[2025-05-13 01:29:01,536][INFO    ][coiled] Uploading coiled_local_win32...\n",
      "[2025-05-13 01:29:02,377][INFO    ][coiled] Requesting package sync build...\n",
      "[2025-05-13 01:29:03,600][INFO    ][coiled] Creating Cluster (name: hamza-burney1-107c349e, https://cloud.coiled.io/clusters/876327 ). This usually takes 1-2 minutes...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Note</span>: You're currently using <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Coiled-hosted</span>, a sandbox for running computations on our cloud infrastructure.\n",
       "When you're ready to use Coiled in your own cloud provider account <span style=\"font-weight: bold\">(</span>AWS, Azure, or Google Cloud<span style=\"font-weight: bold\">)</span>, you can run \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">coiled setup</span> or visit <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://cloud.coiled.io/settings/setup</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mNote\u001b[0m: You're currently using \u001b[1;34mCoiled-hosted\u001b[0m, a sandbox for running computations on our cloud infrastructure.\n",
       "When you're ready to use Coiled in your own cloud provider account \u001b[1m(\u001b[0mAWS, Azure, or Google Cloud\u001b[1m)\u001b[0m, you can run \n",
       "\u001b[32mcoiled setup\u001b[0m or visit \u001b[4;94mhttps://cloud.coiled.io/settings/setup\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster = coiled.Cluster(n_workers=60)\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfd00fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fe90205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40045, 955)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"pdc_dataset_with_target.csv\")\n",
    "\n",
    "num_duplicates = df.duplicated().sum()\n",
    "filtered_df_no_duplicates = df.drop_duplicates()\n",
    "rows_removed_due_to_duplicates = df.shape[0] - filtered_df_no_duplicates.shape[0]\n",
    "df = filtered_df_no_duplicates\n",
    "filtered_df_no_duplicates.shape[0], rows_removed_due_to_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "416b7542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1    0\n",
       "feature_2    0\n",
       "feature_3    0\n",
       "feature_4    0\n",
       "feature_5    0\n",
       "feature_6    0\n",
       "feature_7    0\n",
       "target       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f87041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column definitions\n",
    "numerical_cols = ['feature_1', 'feature_2', 'feature_4', 'feature_6','feature_7']\n",
    "categorical_cols = ['feature_3', 'feature_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c9c6c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df, cols):\n",
    "    filtered_df = df.copy()\n",
    "    for col in cols:\n",
    "        Q1 = filtered_df[col].quantile(0.25)\n",
    "        Q3 = filtered_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        filtered_df = filtered_df[(filtered_df[col] >= lower_bound) & (filtered_df[col] <= upper_bound)]\n",
    "    return filtered_df\n",
    "\n",
    "df = remove_outliers_iqr(df, numerical_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "006c35d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Column definitions\n",
    "numerical_cols = ['feature_1', 'feature_2', 'feature_4', 'feature_7']\n",
    "categorical_cols = ['feature_3', 'feature_5']\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_cols),\n",
    "    ('cat', categorical_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# Apply preprocessing once\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d589ca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time: 0.43 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "336a8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging setup\n",
    "resource_logs = {\n",
    "    'cpu': [],\n",
    "    'mem': [],\n",
    "    'threads': [],\n",
    "    'time': []\n",
    "}\n",
    "\n",
    "def log_resources():\n",
    "    cpu = psutil.cpu_percent(interval=1)\n",
    "    mem = psutil.virtual_memory().percent\n",
    "    threads = psutil.Process().num_threads()\n",
    "    resource_logs['cpu'].append(cpu)\n",
    "    resource_logs['mem'].append(mem)\n",
    "    resource_logs['threads'].append(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d767de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP 640 G5\\AppData\\Local\\Temp\\ipykernel_22372\\4268965580.py:2: ExperimentalWarning: DaskStorage is experimental (supported from v3.1.0). The interface can change in the future.\n",
      "  dask_storage = optuna.integration.DaskStorage(storage=backend_storage)\n",
      "c:\\Users\\HP 640 G5\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\tokenize.py:245: ExperimentalWarning: DaskStorage is experimental (supported from v3.1.0). The interface can change in the future.\n",
      "  mod.loads(out, buffers=buffers)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_depth': 4, 'learning_rate': 0.014471185363828597, 'n_estimators': 267, 'subsample': 0.9228559072464841, 'colsample_bytree': 0.6267972881208569}\n",
      "Best Accuracy: 0.6032140490390987\n",
      "ROC AUC: 0.5030952814352807\n",
      "Confusion Matrix: [[3635, 3], [2392, 6]]\n",
      "Classification Report:\n",
      "{'0': {'f1-score': 0.752198654940507,\n",
      "       'precision': 0.6031192964990875,\n",
      "       'recall': 0.9991753710830127,\n",
      "       'support': 3638.0},\n",
      " '1': {'f1-score': 0.004985459077690071,\n",
      "       'precision': 0.6666666666666666,\n",
      "       'recall': 0.0025020850708924102,\n",
      "       'support': 2398.0},\n",
      " 'accuracy': 0.6032140490390987,\n",
      " 'macro avg': {'f1-score': 0.37859205700909854,\n",
      "               'precision': 0.634892981582877,\n",
      "               'recall': 0.5008387280769525,\n",
      "               'support': 6036.0},\n",
      " 'weighted avg': {'f1-score': 0.4553435781215814,\n",
      "                  'precision': 0.6283655843820986,\n",
      "                  'recall': 0.6032140490390987,\n",
      "                  'support': 6036.0}}\n"
     ]
    }
   ],
   "source": [
    "backend_storage = optuna.storages.InMemoryStorage()\n",
    "dask_storage = optuna.integration.DaskStorage(storage=backend_storage)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=dask_storage,  # This makes the study Dask-enabled\n",
    "    sampler=optuna.samplers.RandomSampler(),\n",
    ")\n",
    "\n",
    "# Define Optuna objective\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'eval_metric': 'logloss',\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0)\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(n_jobs=-1, **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    probas = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    auc = roc_auc_score(y_test, probas)\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "    \n",
    "    # Store additional metrics in the trial\n",
    "    trial.set_user_attr(\"roc_auc\", auc)\n",
    "    trial.set_user_attr(\"confusion_matrix\", cm.tolist())\n",
    "    trial.set_user_attr(\"classification_report\", report)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "futures = [\n",
    "    client.submit(study.optimize, objective, n_trials=5, pure=False) for _ in range(100)\n",
    "]\n",
    "\n",
    "_ = wait(futures)\n",
    "\n",
    "\n",
    "print(\"Best Params:\", study.best_params)\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(\"Best Accuracy:\", best_trial.value)\n",
    "print(\"ROC AUC:\", best_trial.user_attrs[\"roc_auc\"])\n",
    "print(\"Confusion Matrix:\", best_trial.user_attrs[\"confusion_matrix\"])\n",
    "print(\"Classification Report:\")\n",
    "from pprint import pprint\n",
    "pprint(best_trial.user_attrs[\"classification_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f11fa409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time: 127.23 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06141be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-13 01:32:56,806][INFO    ][coiled] Cluster 876327 deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
